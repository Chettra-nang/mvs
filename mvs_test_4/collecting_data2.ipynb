{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8e524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDL_VIDEODRIVER (env): None\n",
      "pygame video driver: x11\n"
     ]
    }
   ],
   "source": [
    "# collector.py — intersection-v1 dataset (grayscale), multi-agent with one EGO\n",
    "# -----------------------------------------------------------------------------\n",
    "# Paper config:\n",
    "#   Observation: Grayscale (128, 64), stack_size: 4\n",
    "#   Action type: DiscreteMetaAction (LANE_LEFT, IDLE, LANE_RIGHT, FASTER, SLOWER)\n",
    "#   Duration: 30s, Sim/Policy freq: 15 Hz, Vehicles: 5, Spawn prob: 0.2\n",
    "#\n",
    "# What this script does:\n",
    "#   • Builds intersection env (v1/v0) with those settings (multi-agent capable)\n",
    "#   • Ensures there are N controlled agents; agent[0] is the EGO “ambulance”\n",
    "#   • Other cars “open the road” (yield/right-bias/slow near ambulance)\n",
    "#   • Steps the env with balanced labels across 5 actions\n",
    "#   • Saves the **last grayscale frame** in the stack as a PNG (128×64)\n",
    "#   • If obs grayscale is blank, falls back to RGB render → grayscale\n",
    "#   • Writes a single JSONL with rows: {image, action_id, instruction, meta…}\n",
    "#\n",
    "# Jupyter-friendly: no argparse. Just run the last cell that calls collect_intersection().\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import os, json, random, math\n",
    "from pathlib import Path\n",
    "from collections import Counter, deque\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import highway_env  # registers env ids\n",
    "\n",
    "import os, pygame\n",
    "print(\"SDL_VIDEODRIVER (env):\", os.environ.get(\"SDL_VIDEODRIVER\"))\n",
    "pygame.init()\n",
    "print(\"pygame video driver:\", pygame.display.get_driver())\n",
    "\n",
    "\n",
    "# -------------------- knobs you can tweak --------------------\n",
    "OUTDIR                 = \"/home/chettra/ITC/mvs-manus/mvs_test_4/data\"  # root folder\n",
    "FRAMES_TOTAL           = 1000                           # <- as requested\n",
    "N_CONTROLLED           = 3                              # agent[0] is EGO\n",
    "SAVE_SIZE              = (128, 64)                      # paper image size (W,H)\n",
    "STACK_SIZE             = 4\n",
    "SEED                   = 42\n",
    "\n",
    "COURTESY_ON            = True   # NPCs yield to ambulance\n",
    "COURTESY_RADIUS        = 60.0\n",
    "COURTESY_SLOW_FACTOR   = 0.6\n",
    "COURTESY_HEADWAY_MULT  = 1.5\n",
    "RIGHT_LANE_BIAS        = True\n",
    "\n",
    "# Action labels (paper order; robust mapping created automatically)\n",
    "ACTION_IDS = [\"SLOWER\", \"IDLE\", \"FASTER\", \"LANE_LEFT\", \"LANE_RIGHT\"]\n",
    "\n",
    "PROMPTS = {\n",
    "    \"SLOWER\":     \"Reduce speed—collision risk ahead.\",\n",
    "    \"IDLE\":       \"Keep the current lane and speed.\",\n",
    "    \"FASTER\":     \"Accelerate; a safe gap is ahead.\",\n",
    "    \"LANE_LEFT\":  \"Change to the left lane.\",\n",
    "    \"LANE_RIGHT\": \"Change to the right lane.\",\n",
    "}\n",
    "PARAPHRASES = {\n",
    "    \"SLOWER\": [\n",
    "        \"Reduce speed—caution ahead.\", \"Back off the throttle; traffic up ahead.\",\n",
    "        \"Slow down to stay safe.\", \"Drop speed; the gap is tight.\", \"Decelerate—possible hazard ahead.\"\n",
    "    ],\n",
    "    \"IDLE\": [\n",
    "        \"Hold speed and lane.\", \"Stay steady in this lane.\", \"Maintain pace; no lane change.\",\n",
    "        \"Remain in lane with current speed.\", \"Continue unchanged.\"\n",
    "    ],\n",
    "    \"FASTER\": [\n",
    "        \"Accelerate—path looks clear.\", \"Increase speed; safe gap ahead.\",\n",
    "        \"Pick up pace—no blockers.\", \"Go quicker; open stretch ahead.\", \"Speed up to target pace.\"\n",
    "    ],\n",
    "    \"LANE_LEFT\": [\n",
    "        \"Merge left safely.\", \"Move to the left lane.\", \"Shift to left lane to pass.\"\n",
    "    ],\n",
    "    \"LANE_RIGHT\": [\n",
    "        \"Merge right safely.\", \"Move to the right lane.\", \"Shift to right lane to yield.\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# -------------------- small utils --------------------\n",
    "def set_all_seeds(s: int = 42):\n",
    "    random.seed(s); np.random.seed(s)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def to_gray_uint8(x: np.ndarray) -> Image.Image:\n",
    "    \"\"\"x can be [0,1] or [0,255], shape (H, W) -> PIL 'L'\"\"\"\n",
    "    arr = np.asarray(x)\n",
    "    if arr.max() <= 1.0: arr = arr * 255.0\n",
    "    arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(arr, mode=\"L\")\n",
    "\n",
    "def last_gray_from_obs(obs: Any) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Works with obs in shapes:\n",
    "      • (S, H, W) or (H, W, S)  (paper grayscale stack)\n",
    "      • list/tuple for multi-agent — we take ego [0]\n",
    "    Returns (H, W) float in [0,1].\n",
    "    \"\"\"\n",
    "    if isinstance(obs, (list, tuple)):\n",
    "        obs = obs[0]  # ego\n",
    "    a = np.asarray(obs)\n",
    "    if a.ndim == 3 and a.shape[0] == STACK_SIZE:\n",
    "        fr = a[-1]\n",
    "    elif a.ndim == 3 and a.shape[2] == STACK_SIZE:\n",
    "        fr = a[..., -1]\n",
    "    elif a.ndim == 2:\n",
    "        fr = a\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected obs shape: {a.shape}\")\n",
    "    return fr.astype(np.float32) / (255.0 if fr.max() > 1.5 else 1.0)\n",
    "\n",
    "# -------------------- env factory (version-robust) --------------------\n",
    "def grayscale_obs_config():\n",
    "    # Some highway-env versions require 'weights'; newer ones accept/ignore it.\n",
    "    return {\n",
    "        \"type\": \"GrayscaleObservation\",\n",
    "        \"observation_shape\": (64, 128),  # H, W  ← swap\n",
    "        \"stack_size\": STACK_SIZE,\n",
    "        \"weights\": [0.2989, 0.5870, 0.1140],\n",
    "    }\n",
    "\n",
    "# --- fixes for blank grayscale frames ---\n",
    "\n",
    "def rgb_to_gray(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"RGB (H,W,3) in [0..255] or [0..1] -> grayscale (H,W) in [0..1].\"\"\"\n",
    "    arr = img_rgb.astype(np.float32)\n",
    "    if arr.max() > 1.5:\n",
    "        arr = arr / 255.0\n",
    "    r, g, b = arr[..., 0], arr[..., 1], arr[..., 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return np.clip(gray, 0.0, 1.0)\n",
    "\n",
    "def safe_render(env):\n",
    "    \"\"\"Always produce a fresh RGB frame from the viewer.\"\"\"\n",
    "    frame = env.render()\n",
    "    if frame is None:\n",
    "        frame = env.render()\n",
    "    return frame\n",
    "\n",
    "def gray_from_obs_or_render(env, obs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Prefer the grayscale observation (last frame of the stack).\n",
    "    If it looks blank, fall back to converting the RGB render to grayscale.\n",
    "    Returns (H, W) in [0,1].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        g = last_gray_from_obs(obs)\n",
    "        if float(np.nanmax(g)) > 0.02:  # not blank\n",
    "            return g\n",
    "    except Exception:\n",
    "        pass\n",
    "    rgb = env.render()\n",
    "    if rgb is None:\n",
    "        raise RuntimeError(\"render() returned None; cannot build grayscale frame.\")\n",
    "    return rgb_to_gray(rgb)\n",
    "\n",
    "def make_intersection_env(seed=SEED, n_controlled=N_CONTROLLED) -> gym.Env:\n",
    "    cfg = dict(\n",
    "        offscreen_rendering=False,\n",
    "        # these affect render() only (not observation); useful for fallback:\n",
    "        screen_width=700, screen_height=256,\n",
    "        centering_position=[0.5, 0.5],\n",
    "        scaling=3.5,\n",
    "        show_trajectories=False,\n",
    "        render_agent=True,\n",
    "\n",
    "        action=dict(type=\"DiscreteMetaAction\"),\n",
    "        observation=grayscale_obs_config(),   # (128,64), stack=4 — paper\n",
    "        duration=30,\n",
    "        simulation_frequency=15,\n",
    "        policy_frequency=15,\n",
    "        vehicles_count=5,\n",
    "        spawn_probability=0.2,\n",
    "        controlled_vehicles=int(n_controlled),\n",
    "    )\n",
    "    env, last_err = None, None\n",
    "    for env_id in (\"intersection-multi-agent-v1\", \"intersection-multi-agent-v0\"):\n",
    "        for with_render_kw in (True, False):\n",
    "            try:\n",
    "                env = gym.make(env_id, render_mode=(\"rgb_array\" if with_render_kw else None), config=cfg)\n",
    "                env.reset(seed=seed)\n",
    "                return env\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                env = None\n",
    "    raise RuntimeError(f\"Could not create intersection env. Last error: {last_err!r}\")\n",
    "\n",
    "# -------------------- action mapping (robust) --------------------\n",
    "def detect_action_mapping(env: gym.Env) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Returns a mapping like:\n",
    "      {'LANE_LEFT':0, 'IDLE':1, 'LANE_RIGHT':2, 'FASTER':3, 'SLOWER':4}\n",
    "    Works even if the env exposes actions as '0','1','2','3','4'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        aty = env.unwrapped.action_type\n",
    "        if hasattr(aty, \"agents_action_types\") and aty.agents_action_types:\n",
    "            actions = list(aty.agents_action_types[0].actions)\n",
    "        else:\n",
    "            actions = list(aty.actions)\n",
    "        names = []\n",
    "        for a in actions:\n",
    "            if isinstance(a, str):\n",
    "                names.append(a)\n",
    "            else:\n",
    "                nm = getattr(a, \"name\", None)\n",
    "                names.append(nm if isinstance(nm, str) else str(a))\n",
    "    except Exception:\n",
    "        names = [\"LANE_LEFT\", \"IDLE\", \"LANE_RIGHT\", \"FASTER\", \"SLOWER\"]\n",
    "\n",
    "    # If we got ['0','1','2','3','4'], map by standard order:\n",
    "    if all(isinstance(n, str) and n.isdigit() for n in names) and len(names) == 5:\n",
    "        std = [\"LANE_LEFT\", \"IDLE\", \"LANE_RIGHT\", \"FASTER\", \"SLOWER\"]\n",
    "        mapping = {std[i]: i for i in range(5)}\n",
    "    else:\n",
    "        mapping = {n: i for i, n in enumerate(names)}\n",
    "\n",
    "    # Ensure all five labels exist (fallback to standard order where missing)\n",
    "    std = {\"LANE_LEFT\": 0, \"IDLE\": 1, \"LANE_RIGHT\": 2, \"FASTER\": 3, \"SLOWER\": 4}\n",
    "    for k, v in std.items():\n",
    "        mapping.setdefault(k, v)\n",
    "\n",
    "    print(\"[env] Detected action mapping:\", mapping)\n",
    "    return mapping\n",
    "\n",
    "# -------------------- courtesy (NPCs open road) --------------------\n",
    "def apply_courtesy(env: gym.Env,\n",
    "                   radius=COURTESY_RADIUS,\n",
    "                   slow_factor=COURTESY_SLOW_FACTOR,\n",
    "                   headway_mult=COURTESY_HEADWAY_MULT,\n",
    "                   right_bias=RIGHT_LANE_BIAS):\n",
    "    if not COURTESY_ON: return\n",
    "    try:\n",
    "        road = env.unwrapped.road\n",
    "        cvs  = getattr(env.unwrapped, \"controlled_vehicles\", []) or []\n",
    "        ego  = cvs[0] if cvs else env.unwrapped.vehicle\n",
    "    except Exception:\n",
    "        return\n",
    "    if road is None or ego is None: return\n",
    "    ego_xy = np.asarray(getattr(ego, \"position\", (0.0, 0.0)), dtype=float)\n",
    "\n",
    "    for v in list(road.vehicles):\n",
    "        if v is ego: continue\n",
    "        pos = getattr(v, \"position\", None)\n",
    "        if pos is None: continue\n",
    "        d = float(np.linalg.norm(np.asarray(pos, dtype=float) - ego_xy))\n",
    "        if d > radius: continue\n",
    "\n",
    "        # Slow down / increase headway\n",
    "        if hasattr(v, \"target_speed\"):\n",
    "            try: v.target_speed = max(0.0, float(v.target_speed) * slow_factor)\n",
    "            except Exception: pass\n",
    "        elif hasattr(v, \"speed\"):\n",
    "            try: v.speed = float(v.speed) * slow_factor\n",
    "            except Exception: pass\n",
    "        for attr in (\"T\", \"desired_headway\", \"desired_time_headway\", \"desired_gap\", \"min_gap\", \"s0\"):\n",
    "            if hasattr(v, attr):\n",
    "                try: setattr(v, attr, float(getattr(v, attr)) * headway_mult)\n",
    "                except Exception: pass\n",
    "\n",
    "        # Bias to right-most lane (opens middle/left for ambulance)\n",
    "        if right_bias:\n",
    "            try:\n",
    "                li = getattr(v, \"lane_index\", None)\n",
    "                if isinstance(li, (tuple, list)) and len(li) >= 3:\n",
    "                    cur = int(li[2]); tgt = max(0, cur - 1)\n",
    "                    if tgt < cur:\n",
    "                        if hasattr(v, \"go_to_lane\"): v.go_to_lane(tgt)\n",
    "                        elif hasattr(v, \"target_lane_index\"): v.target_lane_index = (li[0], li[1], tgt)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# -------------------- simple side-agent policy --------------------\n",
    "def side_agent_label(t: int) -> str:\n",
    "    # Mostly IDLE; occasionally nudge lanes to create variety\n",
    "    if t % 25 == 0: return random.choice([\"IDLE\", \"LANE_LEFT\", \"LANE_RIGHT\"])\n",
    "    return \"IDLE\"\n",
    "\n",
    "# -------------------- main collector --------------------\n",
    "def collect_intersection(\n",
    "    outdir: str = OUTDIR,\n",
    "    frames_total: int = FRAMES_TOTAL,\n",
    "    n_controlled: int = N_CONTROLLED,\n",
    "    seed: int = SEED,\n",
    "):\n",
    "    set_all_seeds(seed)\n",
    "    out = Path(outdir); img_dir = out / \"images\"\n",
    "    ensure_dir(img_dir)\n",
    "\n",
    "    env = make_intersection_env(seed=seed, n_controlled=n_controlled)\n",
    "    name2idx = detect_action_mapping(env)\n",
    "\n",
    "    label_counter = Counter()\n",
    "    schedule = deque()  # (action_id, instruction)\n",
    "\n",
    "    # build a balanced schedule across 5 actions, round-robin with paraphrases\n",
    "    per = math.ceil(frames_total / len(ACTION_IDS))\n",
    "    for a in ACTION_IDS:\n",
    "        phrases = [PROMPTS[a]] + PARAPHRASES.get(a, [])\n",
    "        for i in range(per):\n",
    "            schedule.append((a, phrases[i % len(phrases)]))\n",
    "    while len(schedule) > frames_total: schedule.pop()\n",
    "\n",
    "    rows = []\n",
    "    frame_id = 0\n",
    "    ep = 0\n",
    "    pbar = tqdm(total=frames_total, desc=\"Collecting (intersection-v1)\")\n",
    "\n",
    "    while schedule:\n",
    "        obs, info = env.reset(seed=seed + ep)\n",
    "        print(\"reset: obs type/shape =\", type(obs), (np.asarray(obs[0]).shape if isinstance(obs,(list,tuple)) else np.asarray(obs).shape))\n",
    "        done = trunc = False\n",
    "        t = 0\n",
    "\n",
    "        while not (done or trunc) and schedule:\n",
    "            apply_courtesy(env)\n",
    "\n",
    "            # --- choose ego action (balanced) ---\n",
    "            action_id, instruction = schedule[0]\n",
    "            ego_idx = int(name2idx.get(action_id, name2idx.get(\"IDLE\", 1)))\n",
    "            label_counter[action_id] += 1\n",
    "\n",
    "            # --- build multi-agent action vector (ego + side agents) ---\n",
    "            acts = [ego_idx]\n",
    "            for k in range(1, n_controlled):\n",
    "                nm = side_agent_label(t)\n",
    "                acts.append(int(name2idx.get(nm, name2idx.get(\"IDLE\", 1))))\n",
    "\n",
    "            # step (tuple for multi-agent; fallback to int for single-agent builds)\n",
    "            try:\n",
    "                obs, reward, done, trunc, info = env.step(tuple(acts))\n",
    "                \n",
    "            except Exception:\n",
    "                obs, reward, done, trunc, info = env.step(acts[0])\n",
    "\n",
    "            # --- diagnostics (do this e.g. when t == 0 or frame_id < 3) ---\n",
    "            if t == 0:  # or use: if frame_id < 3:\n",
    "                # show obs shape\n",
    "                obs_shape = (np.asarray(obs[0]).shape if isinstance(obs, (list, tuple))\n",
    "                            else np.asarray(obs).shape)\n",
    "                print(\"obs type/shape:\", type(obs), obs_shape)\n",
    "\n",
    "                # try grayscale-from-obs\n",
    "                try:\n",
    "                    g = last_gray_from_obs(obs)\n",
    "                    print(\"obs gray max:\", float(np.nanmax(g)))\n",
    "                except Exception as e:\n",
    "                    print(\"last_gray_from_obs failed:\", e)\n",
    "\n",
    "                # try render (can be None/black in headless)\n",
    "                try:\n",
    "                    r = env.render()\n",
    "                    if r is None:\n",
    "                        print(\"render() returned None\")\n",
    "                    else:\n",
    "                        r_arr = np.asarray(r)\n",
    "                        print(\"render shape:\", r_arr.shape, \"render max:\", float(np.nanmax(r_arr)))\n",
    "                except Exception as e:\n",
    "                    print(\"render() failed:\", e)\n",
    "\n",
    "            # --- SAVE FULL RENDER FRAME INSTEAD OF OBS CROP ---\n",
    "            rgb = env.render()  # get full simulator screen\n",
    "            if rgb is None:\n",
    "                rgb = env.render()  # safety retry\n",
    "\n",
    "            # convert to grayscale or keep color\n",
    "            pil = Image.fromarray(rgb)  # full view, same as human render\n",
    "            pil = pil.resize(SAVE_SIZE, Image.BILINEAR)\n",
    "            # pil = Image.fromarray(rgb).convert(\"L\")  # uncomment if you want grayscale\n",
    "\n",
    "            fname = f\"f_{frame_id:06d}.png\"\n",
    "            pil.save(img_dir / fname)\n",
    "            # -------------------------------------------------\n",
    "\n",
    "            # write a row (ego label); include a bit of env state\n",
    "            try:\n",
    "                ego_speed = float(getattr(env.unwrapped.controlled_vehicles[0], \"speed\", 0.0))\n",
    "            except Exception:\n",
    "                ego_speed = float(info.get(\"speed\", 0.0))\n",
    "\n",
    "            rows.append({\n",
    "                \"index\": frame_id,\n",
    "                \"image\": f\"images/{fname}\",\n",
    "                \"action_id\": action_id,\n",
    "                \"instruction\": instruction,\n",
    "                \"episode\": ep,\n",
    "                \"t\": t,\n",
    "                \"ego_speed\": ego_speed,\n",
    "                \"n_controlled\": n_controlled,\n",
    "                \"courtesy\": bool(COURTESY_ON),\n",
    "            })\n",
    "\n",
    "            frame_id += 1\n",
    "            t += 1\n",
    "            schedule.popleft()\n",
    "            pbar.update(1)\n",
    "            if frame_id >= frames_total: break\n",
    "\n",
    "        ep += 1\n",
    "        if frame_id >= frames_total: break\n",
    "\n",
    "    pbar.close()\n",
    "    env.close()\n",
    "\n",
    "    # JSONL (no splits; you can split later)\n",
    "    ensure_dir(Path(outdir))\n",
    "    with open(Path(outdir) / \"frames.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Done. Saved {frame_id} frames to {outdir}\")\n",
    "    print(\"Label counts:\", dict(label_counter))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7f2703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[env] Detected action mapping: {'LANE_LEFT': 0, 'IDLE': 1, 'LANE_RIGHT': 2, 'FASTER': 3, 'SLOWER': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting (episode-style):  78%|███████▊  | 777/1000 [00:13<00:03, 65.68it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ---- run in Jupyter: just execute this cell ----\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcollect_intersection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTDIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframes_total\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFRAMES_TOTAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_controlled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_CONTROLLED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mcollect_intersection_episode\u001b[39m\u001b[34m(outdir, frames_total, n_episodes, frames_per_episode, n_controlled, seed)\u001b[39m\n\u001b[32m     80\u001b[39m     obs, reward, done, trunc, info = env.step(acts[\u001b[32m0\u001b[39m])\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Render full RGB frame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m rgb = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rgb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m     rgb = env.render()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITC/mvs-manus/mvs_venv/lib/python3.12/site-packages/gymnasium/core.py:337\u001b[39m, in \u001b[36mWrapper.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> RenderFrame | \u001b[38;5;28mlist\u001b[39m[RenderFrame] | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    336\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITC/mvs-manus/mvs_venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:409\u001b[39m, in \u001b[36mOrderEnforcing.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITC/mvs-manus/mvs_venv/lib/python3.12/site-packages/gymnasium/core.py:337\u001b[39m, in \u001b[36mWrapper.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> RenderFrame | \u001b[38;5;28mlist\u001b[39m[RenderFrame] | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    336\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITC/mvs-manus/mvs_venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:303\u001b[39m, in \u001b[36mPassiveEnvChecker.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m.env)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITC/mvs-manus/mvs_venv/lib/python3.12/site-packages/highway_env/envs/common/abstract.py:308\u001b[39m, in \u001b[36mAbstractEnv.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m.viewer.handle_events()\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mrgb_array\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mviewer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_image\u001b[49m()\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get_image'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting (episode-style):  78%|███████▊  | 780/1000 [00:31<00:03, 65.68it/s]"
     ]
    }
   ],
   "source": [
    "# ---- run in Jupyter: just execute this cell ----\n",
    "collect_intersection(\n",
    "    outdir=OUTDIR,\n",
    "    frames_total=FRAMES_TOTAL,\n",
    "    n_controlled=N_CONTROLLED,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29dab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Override collector with episode-style loop from clip-rl-2 (simplified, no Ollama) ---\n",
    "# This cell replaces the previous step-loop collector with an episode-based collector\n",
    "# that uses the PROMPTS / PARAPHRASES defined earlier in the notebook for text labels.\n",
    "\n",
    "def collect_intersection_episode(\n",
    "    outdir: str = OUTDIR,\n",
    "    frames_total: int = None,            # backward-compatible arg used in original run cell\n",
    "    n_episodes: int = 50,\n",
    "    frames_per_episode: int = None,\n",
    "    n_controlled: int = N_CONTROLLED,\n",
    "    seed: int = SEED,\n",
    "):\n",
    "    \"\"\"Episode-style data collector inspired by clip-rl-2 patterns.\n",
    "    - Runs multiple episodes; in each episode, selects actions per step from the\n",
    "      balanced schedule derived from the notebook PROMPTS/PARAPHRASES.\n",
    "    - No Ollama or external LLM used; labels come from PROMPTS/PARAPHRASES.\n",
    "    - Saves PNG renders and a single JSONL dataset at outdir/frames.jsonl\n",
    "\n",
    "    Backwards compatibility:\n",
    "      If `frames_total` is provided (old API), compute `frames_per_episode = ceil(frames_total / n_episodes)`.\n",
    "    \"\"\"\n",
    "    set_all_seeds(seed)\n",
    "    out = Path(outdir); img_dir = out / \"images\"\n",
    "    ensure_dir(img_dir)\n",
    "\n",
    "    # Backwards compatibility handling\n",
    "    if frames_total is not None and frames_per_episode is None:\n",
    "        frames_per_episode = math.ceil(frames_total / max(1, n_episodes))\n",
    "    if frames_per_episode is None:\n",
    "        frames_per_episode = 20\n",
    "\n",
    "    env = make_intersection_env(seed=seed, n_controlled=n_controlled)\n",
    "    name2idx = detect_action_mapping(env)\n",
    "\n",
    "    # Build a per-episode balanced schedule (reused across episodes with shuffling)\n",
    "    base_schedule = []\n",
    "    per = math.ceil((n_episodes * frames_per_episode) / len(ACTION_IDS))\n",
    "    for a in ACTION_IDS:\n",
    "        phrases = [PROMPTS[a]] + PARAPHRASES.get(a, [])\n",
    "        for i in range(per):\n",
    "            base_schedule.append((a, phrases[i % len(phrases)]))\n",
    "\n",
    "    # Shuffle for variety but keep deterministic via seed\n",
    "    random.Random(seed).shuffle(base_schedule)\n",
    "\n",
    "    rows = []\n",
    "    frame_id = 0\n",
    "    pbar = tqdm(total=n_episodes * frames_per_episode, desc=\"Collecting (episode-style)\")\n",
    "\n",
    "    schedule_iter = iter(base_schedule)\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        obs, info = env.reset(seed=seed + ep)\n",
    "        done = trunc = False\n",
    "        t = 0\n",
    "\n",
    "        while t < frames_per_episode:\n",
    "            apply_courtesy(env)\n",
    "\n",
    "            # Get next label from schedule (wrap if needed)\n",
    "            try:\n",
    "                action_id, instruction = next(schedule_iter)\n",
    "            except StopIteration:\n",
    "                # Recreate iterator if we exhausted base_schedule\n",
    "                schedule_iter = iter(base_schedule)\n",
    "                action_id, instruction = next(schedule_iter)\n",
    "\n",
    "            ego_idx = int(name2idx.get(action_id, name2idx.get(\"IDLE\", 1)))\n",
    "\n",
    "            # Build multi-agent actions\n",
    "            acts = [ego_idx]\n",
    "            for k in range(1, n_controlled):\n",
    "                nm = side_agent_label(t)\n",
    "                acts.append(int(name2idx.get(nm, name2idx.get(\"IDLE\", 1))))\n",
    "\n",
    "            # Step environment\n",
    "            try:\n",
    "                obs, reward, done, trunc, info = env.step(tuple(acts))\n",
    "            except Exception:\n",
    "                obs, reward, done, trunc, info = env.step(acts[0])\n",
    "\n",
    "            # Render full RGB frame\n",
    "            rgb = env.render()\n",
    "            if rgb is None:\n",
    "                rgb = env.render()\n",
    "            if rgb is None:\n",
    "                # fallback to grayscale obs -> to RGB-like for saving\n",
    "                try:\n",
    "                    g = gray_from_obs_or_render(env, obs)\n",
    "                    # convert to uint8\n",
    "                    arr = (g * 255.0).astype(np.uint8)\n",
    "                    pil = Image.fromarray(arr).convert(\"RGB\")\n",
    "                except Exception:\n",
    "                    # create a blank image\n",
    "                    pil = Image.new(\"RGB\", SAVE_SIZE, color=(0, 0, 0))\n",
    "            else:\n",
    "                pil = Image.fromarray(rgb).resize(SAVE_SIZE, Image.BILINEAR)\n",
    "\n",
    "            fname = f\"f_{frame_id:06d}.png\"\n",
    "            pil.save(img_dir / fname)\n",
    "\n",
    "            # gather ego speed if possible\n",
    "            try:\n",
    "                ego_speed = float(getattr(env.unwrapped.controlled_vehicles[0], \"speed\", 0.0))\n",
    "            except Exception:\n",
    "                ego_speed = float(info.get(\"speed\", 0.0))\n",
    "\n",
    "            rows.append({\n",
    "                \"index\": frame_id,\n",
    "                \"image\": f\"images/{fname}\",\n",
    "                \"action_id\": action_id,\n",
    "                \"instruction\": instruction,\n",
    "                \"episode\": ep,\n",
    "                \"t\": t,\n",
    "                \"ego_speed\": ego_speed,\n",
    "                \"n_controlled\": n_controlled,\n",
    "                \"courtesy\": bool(COURTESY_ON),\n",
    "            })\n",
    "\n",
    "            frame_id += 1\n",
    "            t += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        if frame_id >= n_episodes * frames_per_episode:\n",
    "            break\n",
    "\n",
    "    pbar.close()\n",
    "    env.close()\n",
    "\n",
    "    # Write JSONL\n",
    "    ensure_dir(Path(outdir))\n",
    "    with open(Path(outdir) / \"frames.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Done. Saved {frame_id} frames to {outdir}\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "# Replace the notebook's collect_intersection reference with the episode variant\n",
    "collect_intersection = collect_intersection_episode\n",
    "\n",
    "# Note: to run, execute the existing run cell which calls collect_intersection()\n",
    "# Example (in notebook):\n",
    "# collect_intersection(outdir=OUTDIR, frames_total=FRAMES_TOTAL, n_controlled=N_CONTROLLED, seed=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cf85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
